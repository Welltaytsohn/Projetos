{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio Cientista de Dados Hospital Albert Einstein\n",
    "\n",
    "Data: 02/02/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a small and straightforward test developed by HIAE to check the basics of machine learning.\n",
    "\n",
    "\n",
    "#### Instructions\n",
    "1. Choose your programming language of interest: R or Python;\n",
    "2. Your results can be presented in any format. We suggest using a Jupyter\n",
    "Notebook (for Python users) or RMarkDown (for R users);\n",
    "3. Add comments to the main steps of your code (in English);\n",
    "4. Consider that the results will be presented for a non-technical audience so\n",
    "try to emphasize the results of your work in a clear manner.\n",
    "\n",
    "\n",
    "##### Problem Statement\n",
    "Build a classifier model using the given dataset to predict the target classes.\n",
    "1. Choose two different models of your choice to solve the problem;\n",
    "2. Give a brief explanation of why you picked them;\n",
    "3. Compare and argue over the results of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.71</td>\n",
       "      <td>10.39</td>\n",
       "      <td>-36.45</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.88</td>\n",
       "      <td>5.76</td>\n",
       "      <td>-54.63</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>82.87</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.83</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12.99</td>\n",
       "      <td>10.40</td>\n",
       "      <td>-59.60</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60.10</td>\n",
       "      <td>8.84</td>\n",
       "      <td>-45.87</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1     x2     x3 target\n",
       "0   2.71  10.39 -36.45    med\n",
       "1   9.88   5.76 -54.63    med\n",
       "2  82.87   1.73   0.83    med\n",
       "3  12.99  10.40 -59.60    med\n",
       "4  60.10   8.84 -45.87    med"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carrega os dados\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv('df_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>42.669613</td>\n",
       "      <td>9.023236</td>\n",
       "      <td>-24.603198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>25.597848</td>\n",
       "      <td>5.180151</td>\n",
       "      <td>20.138584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-19.500000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>-59.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>21.675000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>-41.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>42.940000</td>\n",
       "      <td>8.075000</td>\n",
       "      <td>-24.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>64.135000</td>\n",
       "      <td>11.730000</td>\n",
       "      <td>-7.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>101.520000</td>\n",
       "      <td>43.080000</td>\n",
       "      <td>9.990000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x1            x2            x3\n",
       "count  10000.000000  10000.000000  10000.000000\n",
       "mean      42.669613      9.023236    -24.603198\n",
       "std       25.597848      5.180151     20.138584\n",
       "min      -19.500000      0.170000    -59.980000\n",
       "25%       21.675000      5.260000    -41.920000\n",
       "50%       42.940000      8.075000    -24.555000\n",
       "75%       64.135000     11.730000     -7.080000\n",
       "max      101.520000     43.080000      9.990000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descrição das estatísticas básicas\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low     6000\n",
       "high    3000\n",
       "med     1000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribuição da variável Target\n",
    "\n",
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifica existência de valores NaN\n",
    "\n",
    "for column in df:\n",
    "    if df[column].isnull().any():\n",
    "       print('{0} has {1} null values'.format(column, df[column].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoder para transformar variáveis com formato string em números\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "list_encoder = ['target']\n",
    "\n",
    "for col in list_encoder:\n",
    "    X = df.loc[:, [col]].values\n",
    "    le = LabelEncoder()\n",
    "    X[:, 0] = le.fit_transform(X[:, 0])\n",
    "    df[col] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variável</th>\n",
       "      <th>quantidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>x2</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variável  quantidade\n",
       "0       x2         104"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A função abaixo verifica a existência de valores outliers em cada coluna\n",
    "\n",
    "def detect_outlier(data, threshold=3):\n",
    "    df_outlier = pd.DataFrame()\n",
    "    \n",
    "    for col in data.columns:\n",
    "        mean, std = np.mean(data[col]), np.std(data[col])\n",
    "        outliers=[]\n",
    "        \n",
    "        for y in data[col]:\n",
    "            z_score = (y - mean)/std\n",
    "            \n",
    "            if np.abs(z_score) > threshold or np.abs(z_score) < - threshold:  \n",
    "                outliers.append(y)\n",
    "        df2 = pd.DataFrame({'variável': [col], 'quantidade': [len(set(outliers))]})\n",
    "        df_outlier = df_outlier.append(df2)\n",
    "        df_outlier = df_outlier.loc[df_outlier.quantidade > 0]  \n",
    "          \n",
    "    return df_outlier\n",
    "\n",
    "outliers = detect_outlier(df)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesmo que encontrado valores outliers, nenhuma ação foi seguida, visto que alguns testes foram feitos, como por exemplo substituição dos valores discrepantes pela média da variável, e o resultado foi bem similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>x1</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.304</td>\n",
       "      <td>-0.824</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.949</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x2</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.248</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x3</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>-0.434</td>\n",
       "      <td>0.363</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.729</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count   mean    std    min    25%    50%    75%   max\n",
       "x1  10000.0  0.719  0.304 -0.824  0.588  0.829  0.949  1.00\n",
       "x2  10000.0  0.199  0.175  0.000  0.085  0.146  0.248  1.00\n",
       "x3  10000.0 -0.434  0.363 -1.000 -0.729 -0.475 -0.149  0.97"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalização dos dados\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "df = df.astype(int)\n",
    "numeric_columns = ['x1', 'x2', 'x3']\n",
    "\n",
    "scaler = Normalizer().fit(df[numeric_columns].values)\n",
    "standardX = scaler.transform(df[numeric_columns].values)\n",
    "df[numeric_columns] = standardX\n",
    "round(df[numeric_columns].describe().T,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As Variáveis mais importantes são ['x1', 'x3', 'x2']\n"
     ]
    }
   ],
   "source": [
    "# Verificando a importância dos Atributos com o Extra Trees Classifier\n",
    "\n",
    "# Import dos Módulos\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "\n",
    "X = df.drop(['target'], axis=1).values\n",
    "Y = df.target.values\n",
    "\n",
    "# Criação do Modelo - Feature Selection\n",
    "modelo = ExtraTreesClassifier()\n",
    "modelo.fit(X, Y)\n",
    "\n",
    "X_features = df.drop(['target'], axis=1)\n",
    "\n",
    "# Lista de colunas a serem usadas para treinar cada modelo\n",
    "features = [col for col in list(X_features) ]\n",
    "importances =  modelo.feature_importances_\n",
    "descending_indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = [importances[idx] for idx in descending_indices]\n",
    "sorted_features = [features[idx] for idx in descending_indices]\n",
    "print('As Variáveis mais importantes são %s' % sorted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot das variáveis em um eixo de impacto nas previsões\n",
    "\n",
    "def plot_importances(X_features, sorted_features, sorted_importances):\n",
    "\n",
    "    axis_width = 1.5\n",
    "    maj_tick_len = 6\n",
    "    fontsize = 14\n",
    "    bar_color = 'blue'\n",
    "    align = 'center'\n",
    "    label = '__nolegend__'\n",
    "    ax = plt.bar(range(X_features.shape[1]), sorted_importances, color=bar_color, align=align, label=label)\n",
    "    ax = plt.xticks(range(X_features.shape[1]), sorted_features, rotation=85)\n",
    "    ax = plt.xlim([-1, X_features.shape[1]])\n",
    "    ax = plt.ylabel('Feature Importance', fontsize=fontsize)\n",
    "    ax = plt.tick_params('both', length=maj_tick_len, width=axis_width, which='major', right=True, top=True)\n",
    "    ax = plt.xticks(fontsize=fontsize)\n",
    "    ax = plt.yticks(fontsize=fontsize)\n",
    "    ax = plt.tight_layout()\n",
    "    return ax\n",
    "\n",
    "fig1 = plt.figure(1, figsize=(10,7))\n",
    "ax = plot_importances(X_features, sorted_features, sorted_importances)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo testa 3 algoritmos diferentes, utilizando uma técnica de cross validation.\n",
    "\n",
    "Essa etapa ajuda a identificar as diferentes performances de cada algoritmo e a escolha adequada.\n",
    "\n",
    "Para cada algoritmo, 5 conjuntos de dados de treinamento e teste distintos e aleatórios serão gerados para previsão e avaliação de cada um dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.520800 0.528000 (0.004986)\n",
      "DecisionTree: 0.453600 0.463500 (0.008969)\n",
      "RandomForest: 0.517800 0.533000 (0.008920)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "X = df.drop(['target'], axis=1).values\n",
    "Y = df.target.values\n",
    "\n",
    "num_folds = 5\n",
    "modelos = []\n",
    "resultados = []\n",
    "nomes = []\n",
    "\n",
    "modelos.append(('KNN', KNeighborsClassifier()))\n",
    "modelos.append(('DecisionTree', DecisionTreeClassifier()))\n",
    "modelos.append(('RandomForest', RandomForestClassifier(n_estimators=100)))\n",
    "\n",
    "for nome, modelo in modelos:\n",
    "    kfold = KFold(num_folds, True)\n",
    "    cv_results = cross_val_score(modelo, X, Y, cv = kfold, scoring = 'accuracy')\n",
    "    resultados.append(cv_results)\n",
    "    nomes.append(nome)\n",
    "    msg = \"%s: %f %f (%f)\" % (nome, cv_results.mean(), cv_results.max(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguindo com o KNN, abaixo temos outros resultados de avaliação do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 253  658   17]\n",
      " [ 489 1282   19]\n",
      " [  75  204    3]] \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.27      0.29       928\n",
      "           1       0.60      0.72      0.65      1790\n",
      "           2       0.08      0.01      0.02       282\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.33      0.33      0.32      3000\n",
      "weighted avg       0.46      0.51      0.48      3000\n",
      " \n",
      "\n",
      "Accuracy: 0.5126666666666667\n"
     ]
    }
   ],
   "source": [
    "# Divisão em dados de treino e de teste\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_treino, testeData, Y_treino, testeLabels = train_test_split(X, Y, test_size = 0.30)\n",
    "\n",
    "# treino do modelo final e previsões nos dados de teste\n",
    "\n",
    "modeloKNN = KNeighborsClassifier()\n",
    "modeloKNN.fit(X_treino, Y_treino)\n",
    "\n",
    "ypred = modeloKNN.predict(testeData)\n",
    "\n",
    "# Avaliação do modelo\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "ConfusionMatrix = confusion_matrix(testeLabels, ypred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(ConfusionMatrix, '\\n')\n",
    "\n",
    "ClassificationReport = classification_report(testeLabels, ypred)\n",
    "print(\"Classification Report:\",)\n",
    "print (ClassificationReport, '\\n')\n",
    "\n",
    "accuracy = accuracy_score(testeLabels, ypred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao analisarmos o f1-score do modelo acima, podemos notar que há uma permormace ruim para as previsões quando a variável target é igual a 0 ou igual 2, isso porque as classes estão desbalanceadas, como pode ser visto abaixo, o modelo aprende muito mais sobre dados onde a previsão da variável target é igual a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6000\n",
       "0    3000\n",
       "2    1000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribuição da variável target nos dados de treino:\n",
    "\n",
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas técnicas distintas podem ser aplicadas pra resolver esse problema, como coleta de amostras aleatórias dentro do próprio dataset de treino, mas como o volume de dados é pequeno, resolvi aplicar SMOTE que cria dados sintéticos de acordo com cada variável no dataset em questão, igualando as classes a serem previstas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 6000, 1: 6000, 0: 6000})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "oversample = SMOTE()\n",
    "X, Y = oversample.fit_resample(X, Y)\n",
    "counter = Counter(Y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1098  388  273]\n",
      " [ 754  661  400]\n",
      " [ 355  296 1175]] \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.62      0.55      1759\n",
      "           1       0.49      0.36      0.42      1815\n",
      "           2       0.64      0.64      0.64      1826\n",
      "\n",
      "    accuracy                           0.54      5400\n",
      "   macro avg       0.54      0.54      0.54      5400\n",
      "weighted avg       0.54      0.54      0.54      5400\n",
      " \n",
      "\n",
      "Accuracy: 0.5433333333333333\n"
     ]
    }
   ],
   "source": [
    "# treino do modelo com o dataset balanceado e previsões nos dados de teste\n",
    "\n",
    "X_treino, testeData, Y_treino, testeLabels = train_test_split(X, Y, test_size = 0.30)\n",
    "modeloKNN = KNeighborsClassifier()\n",
    "modeloKNN.fit(X_treino, Y_treino)\n",
    "ypred = modeloKNN.predict(testeData)\n",
    "\n",
    "# Avaliação do modelo\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "ConfusionMatrix = confusion_matrix(testeLabels, ypred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(ConfusionMatrix, '\\n')\n",
    "\n",
    "ClassificationReport = classification_report(testeLabels, ypred)\n",
    "print(\"Classification Report:\",)\n",
    "print (ClassificationReport, '\\n')\n",
    "\n",
    "accuracy = accuracy_score(testeLabels, ypred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora com os dados balanceados, podemos otimizar o valor de k para otimizar os resultados do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Com valor de k = 3, a acurácia é = 55.56%\n",
      "Com valor de k = 5, a acurácia é = 55.15%\n",
      "Com valor de k = 7, a acurácia é = 53.37%\n",
      "Com valor de k = 9, a acurácia é = 52.06%\n",
      "Com valor de k = 11, a acurácia é = 51.13%\n",
      "Com valor de k = 13, a acurácia é = 50.87%\n",
      "Com valor de k = 15, a acurácia é = 50.28%\n",
      "Com valor de k = 17, a acurácia é = 50.09%\n",
      "Com valor de k = 19, a acurácia é = 49.41%\n",
      "Com valor de k = 21, a acurácia é = 48.72%\n",
      "Com valor de k = 23, a acurácia é = 48.69%\n",
      "Com valor de k = 25, a acurácia é = 48.04%\n",
      "Com valor de k = 27, a acurácia é = 47.74%\n",
      "Com valor de k = 29, a acurácia é = 47.07%\n"
     ]
    }
   ],
   "source": [
    "# Otimização do valor de K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divisão em dados de treino e de teste\n",
    "X_treino, testeData, Y_treino, testeLabels = train_test_split(X, Y, test_size = 0.30)\n",
    "\n",
    "# Range de valores de k que iremos testar\n",
    "kVals = range(3, 30, 2)\n",
    "\n",
    "# Lista vazia para receber as acurácias\n",
    "acuracias = []\n",
    "\n",
    "# Loop em todos os valores de k para testar cada um deles\n",
    "for k in kVals:\n",
    "    \n",
    "    # Treinando o modelo KNN com cada valor de k\n",
    "    modeloKNN = KNeighborsClassifier(n_neighbors = k)\n",
    "    modeloKNN.fit(X_treino, Y_treino)\n",
    "          \n",
    "    # Avaliando o modelo e atualizando a lista de acurácias\n",
    "    score = modeloKNN.score(testeData, testeLabels)\n",
    "    print(\"Com valor de k = %d, a acurácia é = %.2f%%\" % (k, score * 100))\n",
    "    acuracias.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que conforme o valor de K aumenta, a acurácia do modelo tende a cair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1151  421  252]\n",
      " [ 707  652  447]\n",
      " [ 382  191 1197]] \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.63      0.57      1824\n",
      "           1       0.52      0.36      0.42      1806\n",
      "           2       0.63      0.68      0.65      1770\n",
      "\n",
      "    accuracy                           0.56      5400\n",
      "   macro avg       0.55      0.56      0.55      5400\n",
      "weighted avg       0.55      0.56      0.55      5400\n",
      " \n",
      "\n",
      "Accuracy: 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "# treino do modelo final com k =3 e previsões nos dados de teste\n",
    "\n",
    "modeloKNN = KNeighborsClassifier(n_neighbors = 3)\n",
    "modeloKNN.fit(X_treino, Y_treino)\n",
    "\n",
    "ypred = modeloKNN.predict(testeData)\n",
    "\n",
    "# Avaliação do modelo\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "ConfusionMatrix = confusion_matrix(testeLabels, ypred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(ConfusionMatrix, '\\n')\n",
    "\n",
    "ClassificationReport = classification_report(testeLabels, ypred)\n",
    "print(\"Classification Report:\",)\n",
    "print (ClassificationReport, '\\n')\n",
    "\n",
    "accuracy = accuracy_score(testeLabels, ypred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É notável o ganho de performance entre os modelos criados a cada otimização realizada, principalmente na etapa de balanceamento das classes.O f1-score do modelo para previsão do classe 'med' teve um ganho de performance gigantesco em comparação ao primeiro modelo com os as classes desbalanceadas. \n",
    "\n",
    "A etapa de normalização é importante para colocar os dados em uma mesma escala, principalmente quando escolhido utilizar o KNN, que por ter como base de cálculo a distância entre pontos, apresenta resultados e performance melhores com a normalização, essa etapa também trouxe melhorias em todas as métricas do report em comparação ao modelo anterior.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
